{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1vm317KlGez9POPLzyK401b-16hwFUZad",
      "authorship_tag": "ABX9TyMUPh1/6lQM7Zt/00AhnpcC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diogosantanaime/rec_proc/blob/main/flair_conll03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wRmaDXFKRXDO",
        "outputId": "d14b22ca-4502-4e52-b14a-2f05530c6425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flair\n",
            "  Downloading flair-0.12.2-py3-none-any.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.1/373.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from flair) (2.8.2)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from flair) (2.0.1+cu118)\n",
            "Requirement already satisfied: gensim>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.3.1)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.10/dist-packages (from flair) (4.65.0)\n",
            "Collecting segtok>=1.5.7 (from flair)\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from flair) (3.7.1)\n",
            "Collecting mpld3==0.3 (from flair)\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.5/788.5 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from flair) (1.2.2)\n",
            "Collecting sqlitedict>=1.6.0 (from flair)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deprecated>=1.2.4 (from flair)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: hyperopt>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from flair) (0.2.7)\n",
            "Collecting boto3 (from flair)\n",
            "  Downloading boto3-1.26.143-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers[sentencepiece]>=4.18.0 (from flair)\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bpemb>=0.3.2 (from flair)\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from flair) (2022.10.31)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from flair) (0.8.10)\n",
            "Collecting langdetect (from flair)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from flair) (4.9.2)\n",
            "Collecting ftfy (from flair)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting janome (from flair)\n",
            "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gdown==4.4.0 (from flair)\n",
            "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub>=0.10.0 (from flair)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting conllu>=4.0 (from flair)\n",
            "  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from flair) (9.1.0)\n",
            "Collecting wikipedia-api (from flair)\n",
            "  Downloading Wikipedia_API-0.5.8-py3-none-any.whl (13 kB)\n",
            "Collecting pptree (from flair)\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-revgrad (from flair)\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.1 (from flair)\n",
            "  Downloading transformer_smaller_training_vocab-0.2.4-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==4.4.0->flair) (4.11.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair) (1.22.4)\n",
            "Collecting sentencepiece (from bpemb>=0.3.2->flair)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.4->flair) (1.14.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.8.0->flair) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=3.8.0->flair) (6.3.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (2023.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->flair) (23.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt>=0.2.7->flair) (0.10.9.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->flair) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.5.0->flair) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.8,>=1.5.0->flair) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.8,>=1.5.0->flair) (16.0.5)\n",
            "Collecting datasets<3.0.0,>=2.0.0 (from transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[sentencepiece]>=4.18.0->flair)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<=3.20.2 (from transformers[sentencepiece]>=4.18.0->flair)\n",
            "  Downloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.143 (from boto3->flair)\n",
            "  Downloading botocore-1.29.143-py3-none-any.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->flair)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->flair)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->flair) (0.2.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.143->boto3->flair) (1.26.15)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (1.5.3)\n",
            "Collecting xxhash (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (3.4)\n",
            "Collecting accelerate>=0.19.0 (from transformers[sentencepiece]>=4.18.0->flair)\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==4.4.0->flair) (2.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.8,>=1.5.0->flair) (2.1.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==4.4.0->flair) (1.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.8,>=1.5.0->flair) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->transformers[sentencepiece]>=4.18.0->flair) (5.9.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.0.0->transformer-smaller-training-vocab>=0.2.1->flair) (2022.7.1)\n",
            "Building wheels for collected packages: gdown, mpld3, sqlitedict, langdetect, pptree\n",
            "  Building wheel for gdown (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14759 sha256=484c30737a02f28b48efda56839434f451a1fe20ae7cdcd5a1f768c05ab18d80\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/0b/3f/6ddf67a417a5b400b213b0bb772a50276c199a386b12c06bfc\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116685 sha256=fb8f7e64252cac85f2d7950758bae4f7dbb956e51bf3be6aea053a32297d8348\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/92/f7/45d9aac5dcfb1c2a1761a272365599cc7ba1050ce211a3fd9a\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=a1790eeeb3aa185013b5c7244b987a1077f0d9131c70d5c3703014dfe72f8f87\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=d360c92a281843f3a066345e3a6f590b737600290c3f870015d5fe30b583d65d\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4609 sha256=a80b599d1f77157f05c09922741b5d9dfe3440e501f0b2cd91b0d06e4b96ce48\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/b6/0e/6f26eb9e6eb53ff2107a7888d72b5a6a597593956113037828\n",
            "Successfully built gdown mpld3 sqlitedict langdetect pptree\n",
            "Installing collected packages: tokenizers, sqlitedict, sentencepiece, pptree, mpld3, janome, xxhash, segtok, protobuf, multidict, langdetect, jmespath, ftfy, frozenlist, dill, deprecated, conllu, async-timeout, yarl, wikipedia-api, responses, multiprocess, huggingface-hub, botocore, aiosignal, transformers, s3transfer, gdown, bpemb, aiohttp, boto3, datasets, accelerate, transformer-smaller-training-vocab, pytorch-revgrad, flair\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.19.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 boto3-1.26.143 botocore-1.29.143 bpemb-0.3.4 conllu-4.5.2 datasets-2.12.0 deprecated-1.2.14 dill-0.3.6 flair-0.12.2 frozenlist-1.3.3 ftfy-6.1.1 gdown-4.4.0 huggingface-hub-0.14.1 janome-0.4.2 jmespath-1.0.1 langdetect-1.0.9 mpld3-0.3 multidict-6.0.4 multiprocess-0.70.14 pptree-3.1 protobuf-3.20.2 pytorch-revgrad-0.2.0 responses-0.18.0 s3transfer-0.6.1 segtok-1.5.11 sentencepiece-0.1.99 sqlitedict-2.1.0 tokenizers-0.13.3 transformer-smaller-training-vocab-0.2.4 transformers-4.29.2 wikipedia-api-0.5.8 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dataset\n",
            "  Downloading dataset-1.6.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting sqlalchemy<2.0.0,>=1.3.2 (from dataset)\n",
            "  Downloading SQLAlchemy-1.4.48-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=0.6.2 (from dataset)\n",
            "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting banal>=1.0.1 (from dataset)\n",
            "  Downloading banal-1.0.6-py2.py3-none-any.whl (6.1 kB)\n",
            "Collecting Mako (from alembic>=0.6.2->dataset)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=0.6.2->dataset) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<2.0.0,>=1.3.2->dataset) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=0.6.2->dataset) (2.1.2)\n",
            "Installing collected packages: banal, sqlalchemy, Mako, alembic, dataset\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.10\n",
            "    Uninstalling SQLAlchemy-2.0.10:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.10\n",
            "Successfully installed Mako-1.2.4 alembic-1.11.1 banal-1.0.6 dataset-1.6.0 sqlalchemy-1.4.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.datasets import ColumnCorpus\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, FlairEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.data import Corpus\n",
        "from typing import List\n",
        "from flair.optim import SGDW"
      ],
      "metadata": {
        "id": "1cKoh2WCxwF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \".\"\n",
        "\n",
        "columns = {0: \"text\", 1: \"ner\"}\n",
        "\n",
        "corpus = ColumnCorpus(data_folder, columns,\n",
        "                      train_file=\"train.txt\",\n",
        "                      test_file=\"test.txt\",\n",
        "                      dev_file=\"valid.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ypnYg1JxzZO",
        "outputId": "26a782f7-2248-4887-a73c-6d17ca76a1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:34:16,836 Reading data from .\n",
            "2023-05-30 22:34:16,837 Train: train.txt\n",
            "2023-05-30 22:34:16,838 Dev: valid.txt\n",
            "2023-05-30 22:34:16,840 Test: test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define o tipo de tag\n",
        "tag_type = 'ner'\n",
        "\n",
        "# Cria um dicionário de tags usando o corpus combinado\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
        "\n",
        "# Define os tipos de embeddings desejados\n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "    #WordEmbeddings('glove'),\n",
        "    FlairEmbeddings('news-forward'),\n",
        "    FlairEmbeddings('news-backward'),\n",
        "    #PooledFlairEmbeddings('news-forward', pooling='min'),\n",
        "    #PooledFlairEmbeddings('news-backward', pooling='min'),\n",
        "]\n",
        "\n",
        "# Cria as embeddings empilhadas\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H1_yE2NyGOI",
        "outputId": "4419ee6c-284b-4e0b-9fbf-1c3b5d001cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-b0de8fdef70b>:5: DeprecationWarning: Call to deprecated method make_tag_dictionary. (Use 'make_label_dictionary' instead.) -- Deprecated since version 0.8.\n",
            "  tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:34:29,840 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmpjq5gesio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69.7M/69.7M [00:08<00:00, 9.03MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:34:38,732 copying /tmp/tmpjq5gesio to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n",
            "2023-05-30 22:34:38,787 removing temp file /tmp/tmpjq5gesio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:34:51,541 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmpa6ciov8l\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69.7M/69.7M [00:08<00:00, 8.86MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:35:00,615 copying /tmp/tmpa6ciov8l to cache at /root/.flair/embeddings/news-backward-0.4.1.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:35:00,668 removing temp file /tmp/tmpa6ciov8l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagger : SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                       embeddings=embeddings,\n",
        "                                       tag_dictionary=tag_dictionary,\n",
        "                                       tag_type=tag_type,\n",
        "                                       use_crf=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGWSUkz6yJ4g",
        "outputId": "35017705-900b-4438-fc50-59d71fe313e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:35:05,935 SequenceTagger predicts: Dictionary with 49 tags: O, -X-, NNP, VBZ, JJ, NN, TO, VB, ., CD, DT, VBD, IN, PRP, NNS, VBP, MD, VBN, POS, JJR, \", RB, ,, FW, CC, WDT, (, ), :, PRP$, RBR, VBG, EX, WP, WRB, $, RP, NNPS, SYM, RBS, UH, PDT, '', LS, JJS, WP$, NN|SYM, <START>, <STOP>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
        "trainer.train('resources/taggers/conll_03',\n",
        "              learning_rate=0.1,  # Taxa de aprendizado\n",
        "              mini_batch_size=32,  # Tamanho do mini-batch\n",
        "              optimizer=SGDW,  # Otimizador\n",
        "              max_epochs=10)  # Número máximo de épocas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4IGsJ8tyMgc",
        "outputId": "cd5bc486-2f2f-4b0a-9e27-497af66994e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:35:26,013 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:35:26,015 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (rnn): LSTM(4096, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=49, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2023-05-30 22:35:26,017 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:35:26,019 Corpus: \"Corpus: 14987 train + 3466 dev + 3684 test sentences\"\n",
            "2023-05-30 22:35:26,022 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:35:26,023 Parameters:\n",
            "2023-05-30 22:35:26,025  - learning_rate: \"0.100000\"\n",
            "2023-05-30 22:35:26,026  - mini_batch_size: \"32\"\n",
            "2023-05-30 22:35:26,028  - patience: \"3\"\n",
            "2023-05-30 22:35:26,030  - anneal_factor: \"0.5\"\n",
            "2023-05-30 22:35:26,031  - max_epochs: \"10\"\n",
            "2023-05-30 22:35:26,034  - shuffle: \"True\"\n",
            "2023-05-30 22:35:26,035  - train_with_dev: \"False\"\n",
            "2023-05-30 22:35:26,037  - batch_growth_annealing: \"False\"\n",
            "2023-05-30 22:35:26,039 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:35:26,040 Model training base path: \"resources/taggers/conll_03\"\n",
            "2023-05-30 22:35:26,042 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:35:26,044 Device: cuda:0\n",
            "2023-05-30 22:35:26,045 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:35:26,047 Embeddings storage mode: cpu\n",
            "2023-05-30 22:35:26,048 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/flair/optim.py:132: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)\n",
            "  p.data.add_(-group[\"lr\"], d_p)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:35:39,409 epoch 1 - iter 46/469 - loss 2.66532179 - time (sec): 13.36 - samples/sec: 1433.84 - lr: 0.100000\n",
            "2023-05-30 22:35:52,922 epoch 1 - iter 92/469 - loss 2.04359271 - time (sec): 26.87 - samples/sec: 1436.81 - lr: 0.100000\n",
            "2023-05-30 22:36:04,393 epoch 1 - iter 138/469 - loss 1.70523074 - time (sec): 38.34 - samples/sec: 1471.29 - lr: 0.100000\n",
            "2023-05-30 22:36:14,212 epoch 1 - iter 184/469 - loss 1.48327977 - time (sec): 48.16 - samples/sec: 1517.61 - lr: 0.100000\n",
            "2023-05-30 22:36:25,244 epoch 1 - iter 230/469 - loss 1.32945296 - time (sec): 59.19 - samples/sec: 1528.88 - lr: 0.100000\n",
            "2023-05-30 22:36:39,134 epoch 1 - iter 276/469 - loss 1.19484921 - time (sec): 73.08 - samples/sec: 1538.17 - lr: 0.100000\n",
            "2023-05-30 22:36:55,053 epoch 1 - iter 322/469 - loss 1.09319272 - time (sec): 89.00 - samples/sec: 1503.70 - lr: 0.100000\n",
            "2023-05-30 22:37:08,001 epoch 1 - iter 368/469 - loss 1.01931947 - time (sec): 101.95 - samples/sec: 1505.42 - lr: 0.100000\n",
            "2023-05-30 22:37:24,596 epoch 1 - iter 414/469 - loss 0.94653971 - time (sec): 118.55 - samples/sec: 1497.20 - lr: 0.100000\n",
            "2023-05-30 22:37:41,339 epoch 1 - iter 460/469 - loss 0.88759561 - time (sec): 135.29 - samples/sec: 1485.72 - lr: 0.100000\n",
            "2023-05-30 22:37:43,570 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:37:43,572 EPOCH 1 done: loss 0.8808 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:38<00:00,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:38:22,082 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:38:22,472 DEV : loss 0.32081106305122375 - f1-score (micro avg)  0.9183\n",
            "2023-05-30 22:38:22,650 BAD EPOCHS (no improvement): 0\n",
            "2023-05-30 22:38:22,652 saving best model\n",
            "2023-05-30 22:38:23,084 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:38:26,997 epoch 2 - iter 46/469 - loss 0.41482331 - time (sec): 3.91 - samples/sec: 5018.91 - lr: 0.100000\n",
            "2023-05-30 22:38:31,203 epoch 2 - iter 92/469 - loss 0.41374213 - time (sec): 8.12 - samples/sec: 4978.24 - lr: 0.100000\n",
            "2023-05-30 22:38:34,944 epoch 2 - iter 138/469 - loss 0.41293494 - time (sec): 11.86 - samples/sec: 5055.50 - lr: 0.100000\n",
            "2023-05-30 22:38:38,793 epoch 2 - iter 184/469 - loss 0.40852537 - time (sec): 15.71 - samples/sec: 5069.64 - lr: 0.100000\n",
            "2023-05-30 22:38:42,775 epoch 2 - iter 230/469 - loss 0.39989845 - time (sec): 19.69 - samples/sec: 5111.21 - lr: 0.100000\n",
            "2023-05-30 22:38:46,902 epoch 2 - iter 276/469 - loss 0.39668801 - time (sec): 23.82 - samples/sec: 5064.38 - lr: 0.100000\n",
            "2023-05-30 22:38:50,683 epoch 2 - iter 322/469 - loss 0.39239177 - time (sec): 27.60 - samples/sec: 5084.83 - lr: 0.100000\n",
            "2023-05-30 22:38:54,537 epoch 2 - iter 368/469 - loss 0.38751654 - time (sec): 31.45 - samples/sec: 5105.44 - lr: 0.100000\n",
            "2023-05-30 22:38:58,427 epoch 2 - iter 414/469 - loss 0.38402348 - time (sec): 35.34 - samples/sec: 5098.24 - lr: 0.100000\n",
            "2023-05-30 22:39:02,586 epoch 2 - iter 460/469 - loss 0.37982880 - time (sec): 39.50 - samples/sec: 5084.76 - lr: 0.100000\n",
            "2023-05-30 22:39:03,293 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:39:03,295 EPOCH 2 done: loss 0.3789 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:14<00:00,  7.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:39:17,436 Evaluating as a multi-label problem: False\n",
            "2023-05-30 22:39:17,817 DEV : loss 0.2370283156633377 - f1-score (micro avg)  0.9363\n",
            "2023-05-30 22:39:17,996 BAD EPOCHS (no improvement): 0\n",
            "2023-05-30 22:39:17,997 saving best model\n",
            "2023-05-30 22:39:18,500 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:39:22,559 epoch 3 - iter 46/469 - loss 0.32483719 - time (sec): 4.06 - samples/sec: 5120.68 - lr: 0.100000\n",
            "2023-05-30 22:39:26,486 epoch 3 - iter 92/469 - loss 0.33108780 - time (sec): 7.98 - samples/sec: 5137.17 - lr: 0.100000\n",
            "2023-05-30 22:39:30,428 epoch 3 - iter 138/469 - loss 0.33052222 - time (sec): 11.93 - samples/sec: 5092.03 - lr: 0.100000\n",
            "2023-05-30 22:39:34,317 epoch 3 - iter 184/469 - loss 0.32932028 - time (sec): 15.82 - samples/sec: 5114.26 - lr: 0.100000\n",
            "2023-05-30 22:39:38,370 epoch 3 - iter 230/469 - loss 0.32744796 - time (sec): 19.87 - samples/sec: 5099.96 - lr: 0.100000\n",
            "2023-05-30 22:39:42,580 epoch 3 - iter 276/469 - loss 0.32404572 - time (sec): 24.08 - samples/sec: 5040.10 - lr: 0.100000\n",
            "2023-05-30 22:39:46,543 epoch 3 - iter 322/469 - loss 0.32337780 - time (sec): 28.04 - samples/sec: 5046.71 - lr: 0.100000\n",
            "2023-05-30 22:39:50,423 epoch 3 - iter 368/469 - loss 0.32209749 - time (sec): 31.92 - samples/sec: 5049.64 - lr: 0.100000\n",
            "2023-05-30 22:39:54,375 epoch 3 - iter 414/469 - loss 0.31928738 - time (sec): 35.87 - samples/sec: 5047.92 - lr: 0.100000\n",
            "2023-05-30 22:39:58,450 epoch 3 - iter 460/469 - loss 0.31722585 - time (sec): 39.95 - samples/sec: 5034.41 - lr: 0.100000\n",
            "2023-05-30 22:39:59,165 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:39:59,167 EPOCH 3 done: loss 0.3171 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:12<00:00,  8.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:40:11,864 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:40:12,273 DEV : loss 0.21967707574367523 - f1-score (micro avg)  0.9407\n",
            "2023-05-30 22:40:12,466 BAD EPOCHS (no improvement): 0\n",
            "2023-05-30 22:40:12,469 saving best model\n",
            "2023-05-30 22:40:13,012 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:40:17,262 epoch 4 - iter 46/469 - loss 0.29135417 - time (sec): 4.25 - samples/sec: 4772.18 - lr: 0.100000\n",
            "2023-05-30 22:40:21,179 epoch 4 - iter 92/469 - loss 0.28727965 - time (sec): 8.16 - samples/sec: 4940.57 - lr: 0.100000\n",
            "2023-05-30 22:40:25,302 epoch 4 - iter 138/469 - loss 0.28700105 - time (sec): 12.29 - samples/sec: 4980.67 - lr: 0.100000\n",
            "2023-05-30 22:40:29,196 epoch 4 - iter 184/469 - loss 0.28959992 - time (sec): 16.18 - samples/sec: 5014.82 - lr: 0.100000\n",
            "2023-05-30 22:40:33,216 epoch 4 - iter 230/469 - loss 0.28728448 - time (sec): 20.20 - samples/sec: 5033.46 - lr: 0.100000\n",
            "2023-05-30 22:40:37,106 epoch 4 - iter 276/469 - loss 0.28976736 - time (sec): 24.09 - samples/sec: 5058.53 - lr: 0.100000\n",
            "2023-05-30 22:40:41,170 epoch 4 - iter 322/469 - loss 0.28843694 - time (sec): 28.15 - samples/sec: 5045.21 - lr: 0.100000\n",
            "2023-05-30 22:40:45,013 epoch 4 - iter 368/469 - loss 0.28922108 - time (sec): 32.00 - samples/sec: 5059.89 - lr: 0.100000\n",
            "2023-05-30 22:40:48,730 epoch 4 - iter 414/469 - loss 0.28819619 - time (sec): 35.72 - samples/sec: 5081.67 - lr: 0.100000\n",
            "2023-05-30 22:40:52,669 epoch 4 - iter 460/469 - loss 0.28686265 - time (sec): 39.65 - samples/sec: 5064.57 - lr: 0.100000\n",
            "2023-05-30 22:40:53,475 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:40:53,477 EPOCH 4 done: loss 0.2862 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:14<00:00,  7.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:41:07,804 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:41:08,217 DEV : loss 0.2059210240840912 - f1-score (micro avg)  0.9425\n",
            "2023-05-30 22:41:08,399 BAD EPOCHS (no improvement): 0\n",
            "2023-05-30 22:41:08,401 saving best model\n",
            "2023-05-30 22:41:08,904 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:41:12,884 epoch 5 - iter 46/469 - loss 0.27023501 - time (sec): 3.98 - samples/sec: 4956.31 - lr: 0.100000\n",
            "2023-05-30 22:41:16,749 epoch 5 - iter 92/469 - loss 0.26775044 - time (sec): 7.84 - samples/sec: 5028.28 - lr: 0.100000\n",
            "2023-05-30 22:41:20,770 epoch 5 - iter 138/469 - loss 0.26876212 - time (sec): 11.86 - samples/sec: 5054.26 - lr: 0.100000\n",
            "2023-05-30 22:41:24,785 epoch 5 - iter 184/469 - loss 0.27076412 - time (sec): 15.88 - samples/sec: 5043.24 - lr: 0.100000\n",
            "2023-05-30 22:41:28,673 epoch 5 - iter 230/469 - loss 0.26944694 - time (sec): 19.77 - samples/sec: 5058.11 - lr: 0.100000\n",
            "2023-05-30 22:41:32,471 epoch 5 - iter 276/469 - loss 0.26963109 - time (sec): 23.56 - samples/sec: 5112.89 - lr: 0.100000\n",
            "2023-05-30 22:41:36,445 epoch 5 - iter 322/469 - loss 0.26842162 - time (sec): 27.54 - samples/sec: 5100.55 - lr: 0.100000\n",
            "2023-05-30 22:41:40,375 epoch 5 - iter 368/469 - loss 0.26593159 - time (sec): 31.47 - samples/sec: 5120.26 - lr: 0.100000\n",
            "2023-05-30 22:41:44,214 epoch 5 - iter 414/469 - loss 0.26480804 - time (sec): 35.31 - samples/sec: 5134.14 - lr: 0.100000\n",
            "2023-05-30 22:41:48,166 epoch 5 - iter 460/469 - loss 0.26569262 - time (sec): 39.26 - samples/sec: 5119.72 - lr: 0.100000\n",
            "2023-05-30 22:41:48,933 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:41:48,935 EPOCH 5 done: loss 0.2656 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:12<00:00,  8.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:42:01,356 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:42:01,759 DEV : loss 0.1955457329750061 - f1-score (micro avg)  0.9458\n",
            "2023-05-30 22:42:01,959 BAD EPOCHS (no improvement): 0\n",
            "2023-05-30 22:42:01,961 saving best model\n",
            "2023-05-30 22:42:02,489 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:42:06,530 epoch 6 - iter 46/469 - loss 0.25205743 - time (sec): 4.04 - samples/sec: 4881.80 - lr: 0.100000\n",
            "2023-05-30 22:42:10,334 epoch 6 - iter 92/469 - loss 0.25237117 - time (sec): 7.84 - samples/sec: 5076.97 - lr: 0.100000\n",
            "2023-05-30 22:42:14,095 epoch 6 - iter 138/469 - loss 0.24960144 - time (sec): 11.60 - samples/sec: 5106.71 - lr: 0.100000\n",
            "2023-05-30 22:42:18,197 epoch 6 - iter 184/469 - loss 0.25212257 - time (sec): 15.71 - samples/sec: 5050.00 - lr: 0.100000\n",
            "2023-05-30 22:42:22,115 epoch 6 - iter 230/469 - loss 0.25197002 - time (sec): 19.62 - samples/sec: 5073.58 - lr: 0.100000\n",
            "2023-05-30 22:42:25,945 epoch 6 - iter 276/469 - loss 0.25118486 - time (sec): 23.45 - samples/sec: 5113.63 - lr: 0.100000\n",
            "2023-05-30 22:42:30,009 epoch 6 - iter 322/469 - loss 0.24970542 - time (sec): 27.52 - samples/sec: 5112.73 - lr: 0.100000\n",
            "2023-05-30 22:42:34,147 epoch 6 - iter 368/469 - loss 0.24894178 - time (sec): 31.66 - samples/sec: 5085.77 - lr: 0.100000\n",
            "2023-05-30 22:42:38,021 epoch 6 - iter 414/469 - loss 0.24954364 - time (sec): 35.53 - samples/sec: 5104.53 - lr: 0.100000\n",
            "2023-05-30 22:42:41,876 epoch 6 - iter 460/469 - loss 0.24928008 - time (sec): 39.38 - samples/sec: 5113.40 - lr: 0.100000\n",
            "2023-05-30 22:42:42,544 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:42:42,546 EPOCH 6 done: loss 0.2492 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:12<00:00,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:42:55,121 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:42:55,505 DEV : loss 0.20099389553070068 - f1-score (micro avg)  0.9457\n",
            "2023-05-30 22:42:55,688 BAD EPOCHS (no improvement): 1\n",
            "2023-05-30 22:42:55,689 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:42:59,936 epoch 7 - iter 46/469 - loss 0.24377233 - time (sec): 4.25 - samples/sec: 4502.85 - lr: 0.100000\n",
            "2023-05-30 22:43:04,397 epoch 7 - iter 92/469 - loss 0.24512485 - time (sec): 8.71 - samples/sec: 4450.64 - lr: 0.100000\n",
            "2023-05-30 22:43:08,387 epoch 7 - iter 138/469 - loss 0.24478669 - time (sec): 12.70 - samples/sec: 4653.09 - lr: 0.100000\n",
            "2023-05-30 22:43:12,282 epoch 7 - iter 184/469 - loss 0.24539159 - time (sec): 16.59 - samples/sec: 4804.50 - lr: 0.100000\n",
            "2023-05-30 22:43:16,173 epoch 7 - iter 230/469 - loss 0.24478487 - time (sec): 20.48 - samples/sec: 4857.98 - lr: 0.100000\n",
            "2023-05-30 22:43:20,095 epoch 7 - iter 276/469 - loss 0.24278136 - time (sec): 24.40 - samples/sec: 4898.56 - lr: 0.100000\n",
            "2023-05-30 22:43:23,824 epoch 7 - iter 322/469 - loss 0.24120800 - time (sec): 28.13 - samples/sec: 4943.54 - lr: 0.100000\n",
            "2023-05-30 22:43:27,773 epoch 7 - iter 368/469 - loss 0.23979481 - time (sec): 32.08 - samples/sec: 4979.67 - lr: 0.100000\n",
            "2023-05-30 22:43:31,827 epoch 7 - iter 414/469 - loss 0.23926172 - time (sec): 36.14 - samples/sec: 4980.04 - lr: 0.100000\n",
            "2023-05-30 22:43:35,833 epoch 7 - iter 460/469 - loss 0.23824477 - time (sec): 40.14 - samples/sec: 4997.01 - lr: 0.100000\n",
            "2023-05-30 22:43:36,582 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:43:36,584 EPOCH 7 done: loss 0.2378 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:14<00:00,  7.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:43:50,738 Evaluating as a multi-label problem: False\n",
            "2023-05-30 22:43:51,119 DEV : loss 0.18899358808994293 - f1-score (micro avg)  0.948\n",
            "2023-05-30 22:43:51,296 BAD EPOCHS (no improvement): 0\n",
            "2023-05-30 22:43:51,298 saving best model\n",
            "2023-05-30 22:43:51,784 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:43:55,758 epoch 8 - iter 46/469 - loss 0.23011432 - time (sec): 3.97 - samples/sec: 4999.87 - lr: 0.100000\n",
            "2023-05-30 22:43:59,969 epoch 8 - iter 92/469 - loss 0.22493042 - time (sec): 8.18 - samples/sec: 4914.94 - lr: 0.100000\n",
            "2023-05-30 22:44:04,023 epoch 8 - iter 138/469 - loss 0.22464897 - time (sec): 12.24 - samples/sec: 4991.88 - lr: 0.100000\n",
            "2023-05-30 22:44:07,854 epoch 8 - iter 184/469 - loss 0.22435042 - time (sec): 16.07 - samples/sec: 5071.48 - lr: 0.100000\n",
            "2023-05-30 22:44:11,684 epoch 8 - iter 230/469 - loss 0.22424345 - time (sec): 19.90 - samples/sec: 5114.26 - lr: 0.100000\n",
            "2023-05-30 22:44:15,672 epoch 8 - iter 276/469 - loss 0.22665155 - time (sec): 23.89 - samples/sec: 5075.28 - lr: 0.100000\n",
            "2023-05-30 22:44:19,520 epoch 8 - iter 322/469 - loss 0.22658859 - time (sec): 27.73 - samples/sec: 5094.90 - lr: 0.100000\n",
            "2023-05-30 22:44:23,483 epoch 8 - iter 368/469 - loss 0.22825173 - time (sec): 31.70 - samples/sec: 5099.07 - lr: 0.100000\n",
            "2023-05-30 22:44:27,479 epoch 8 - iter 414/469 - loss 0.22767830 - time (sec): 35.69 - samples/sec: 5078.75 - lr: 0.100000\n",
            "2023-05-30 22:44:31,365 epoch 8 - iter 460/469 - loss 0.22745165 - time (sec): 39.58 - samples/sec: 5086.25 - lr: 0.100000\n",
            "2023-05-30 22:44:32,052 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:44:32,054 EPOCH 8 done: loss 0.2275 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:12<00:00,  8.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:44:44,540 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:44:44,941 DEV : loss 0.18794719874858856 - f1-score (micro avg)  0.9475\n",
            "2023-05-30 22:44:45,122 BAD EPOCHS (no improvement): 1\n",
            "2023-05-30 22:44:45,124 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:44:49,077 epoch 9 - iter 46/469 - loss 0.22085861 - time (sec): 3.95 - samples/sec: 5273.06 - lr: 0.100000\n",
            "2023-05-30 22:44:52,876 epoch 9 - iter 92/469 - loss 0.22330782 - time (sec): 7.75 - samples/sec: 5324.16 - lr: 0.100000\n",
            "2023-05-30 22:44:56,790 epoch 9 - iter 138/469 - loss 0.22089288 - time (sec): 11.66 - samples/sec: 5251.31 - lr: 0.100000\n",
            "2023-05-30 22:45:00,818 epoch 9 - iter 184/469 - loss 0.22138608 - time (sec): 15.69 - samples/sec: 5202.03 - lr: 0.100000\n",
            "2023-05-30 22:45:04,685 epoch 9 - iter 230/469 - loss 0.22068573 - time (sec): 19.56 - samples/sec: 5184.97 - lr: 0.100000\n",
            "2023-05-30 22:45:08,491 epoch 9 - iter 276/469 - loss 0.22088493 - time (sec): 23.37 - samples/sec: 5198.56 - lr: 0.100000\n",
            "2023-05-30 22:45:12,506 epoch 9 - iter 322/469 - loss 0.22099775 - time (sec): 27.38 - samples/sec: 5191.77 - lr: 0.100000\n",
            "2023-05-30 22:45:16,410 epoch 9 - iter 368/469 - loss 0.22185014 - time (sec): 31.28 - samples/sec: 5184.53 - lr: 0.100000\n",
            "2023-05-30 22:45:20,217 epoch 9 - iter 414/469 - loss 0.22072308 - time (sec): 35.09 - samples/sec: 5172.59 - lr: 0.100000\n",
            "2023-05-30 22:45:24,093 epoch 9 - iter 460/469 - loss 0.22092530 - time (sec): 38.97 - samples/sec: 5158.94 - lr: 0.100000\n",
            "2023-05-30 22:45:24,884 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:45:24,885 EPOCH 9 done: loss 0.2212 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:12<00:00,  8.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:45:37,225 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:45:37,632 DEV : loss 0.1829584538936615 - f1-score (micro avg)  0.949\n",
            "2023-05-30 22:45:37,839 BAD EPOCHS (no improvement): 0\n",
            "2023-05-30 22:45:37,841 saving best model\n",
            "2023-05-30 22:45:38,391 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:45:42,441 epoch 10 - iter 46/469 - loss 0.20757014 - time (sec): 4.05 - samples/sec: 5130.97 - lr: 0.100000\n",
            "2023-05-30 22:45:46,337 epoch 10 - iter 92/469 - loss 0.20658222 - time (sec): 7.94 - samples/sec: 5154.66 - lr: 0.100000\n",
            "2023-05-30 22:45:50,312 epoch 10 - iter 138/469 - loss 0.20694669 - time (sec): 11.92 - samples/sec: 5054.19 - lr: 0.100000\n",
            "2023-05-30 22:45:54,778 epoch 10 - iter 184/469 - loss 0.20604767 - time (sec): 16.39 - samples/sec: 4923.56 - lr: 0.100000\n",
            "2023-05-30 22:45:58,676 epoch 10 - iter 230/469 - loss 0.20805162 - time (sec): 20.28 - samples/sec: 4972.63 - lr: 0.100000\n",
            "2023-05-30 22:46:02,471 epoch 10 - iter 276/469 - loss 0.20855839 - time (sec): 24.08 - samples/sec: 5034.46 - lr: 0.100000\n",
            "2023-05-30 22:46:06,400 epoch 10 - iter 322/469 - loss 0.20998598 - time (sec): 28.01 - samples/sec: 5055.88 - lr: 0.100000\n",
            "2023-05-30 22:46:10,298 epoch 10 - iter 368/469 - loss 0.21067408 - time (sec): 31.90 - samples/sec: 5058.73 - lr: 0.100000\n",
            "2023-05-30 22:46:14,163 epoch 10 - iter 414/469 - loss 0.21113761 - time (sec): 35.77 - samples/sec: 5055.10 - lr: 0.100000\n",
            "2023-05-30 22:46:18,068 epoch 10 - iter 460/469 - loss 0.21076251 - time (sec): 39.67 - samples/sec: 5062.39 - lr: 0.100000\n",
            "2023-05-30 22:46:18,768 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:46:18,769 EPOCH 10 done: loss 0.2108 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 109/109 [00:13<00:00,  7.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:46:32,868 Evaluating as a multi-label problem: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:46:33,271 DEV : loss 0.18061773478984833 - f1-score (micro avg)  0.9502\n",
            "2023-05-30 22:46:33,457 BAD EPOCHS (no improvement): 0\n",
            "2023-05-30 22:46:33,459 saving best model\n",
            "2023-05-30 22:46:34,518 ----------------------------------------------------------------------------------------------------\n",
            "2023-05-30 22:46:35,317 SequenceTagger predicts: Dictionary with 49 tags: O, -X-, NNP, VBZ, JJ, NN, TO, VB, ., CD, DT, VBD, IN, PRP, NNS, VBP, MD, VBN, POS, JJR, \", RB, ,, FW, CC, WDT, (, ), :, PRP$, RBR, VBG, EX, WP, WRB, $, RP, NNPS, SYM, RBS, UH, PDT, '', LS, JJS, WP$, NN|SYM, <START>, <STOP>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 116/116 [00:30<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-30 22:47:06,457 Evaluating as a multi-label problem: False\n",
            "2023-05-30 22:47:06,798 0.9477\t0.9477\t0.9477\t0.9477\n",
            "2023-05-30 22:47:06,800 \n",
            "Results:\n",
            "- F-score (micro) 0.9477\n",
            "- F-score (macro) 0.8617\n",
            "- Accuracy 0.9477\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NNP     0.9196    0.9581    0.9385      8595\n",
            "          CD     0.9668    0.9975    0.9819      5962\n",
            "          NN     0.9101    0.9152    0.9126      4931\n",
            "          IN     0.9849    0.9881    0.9865      4018\n",
            "          DT     0.9971    0.9900    0.9935      2799\n",
            "          JJ     0.8813    0.7915    0.8340      2393\n",
            "         NNS     0.9203    0.9453    0.9326      2174\n",
            "         VBD     0.9382    0.9476    0.9429      1699\n",
            "           ,     1.0000    1.0000    1.0000      1637\n",
            "           .     1.0000    1.0000    1.0000      1630\n",
            "          VB     0.9556    0.8767    0.9145       933\n",
            "          RB     0.8838    0.8480    0.8655       888\n",
            "         VBN     0.8844    0.8303    0.8565       866\n",
            "          TO     1.0000    0.9976    0.9988       818\n",
            "          CC     1.0000    0.9935    0.9967       765\n",
            "           (     1.0000    1.0000    1.0000       688\n",
            "           )     1.0000    1.0000    1.0000       686\n",
            "           :     1.0000    1.0000    1.0000       599\n",
            "         PRP     0.9949    0.9719    0.9833       605\n",
            "         VBG     0.9183    0.8822    0.8999       484\n",
            "         VBZ     0.9434    0.8307    0.8835       502\n",
            "           \"     1.0000    1.0000    1.0000       421\n",
            "         POS     0.9633    0.9827    0.9729       347\n",
            "         VBP     0.8957    0.8822    0.8889       331\n",
            "        PRP$     1.0000    0.9966    0.9983       296\n",
            "          MD     0.9851    0.9888    0.9870       268\n",
            "         -X-     1.0000    1.0000    1.0000       231\n",
            "        NNPS     0.6505    0.4188    0.5095       160\n",
            "         SYM     0.9829    0.9829    0.9829       117\n",
            "          WP     1.0000    0.9912    0.9956       114\n",
            "         WDT     0.9623    0.9444    0.9533       108\n",
            "         JJR     0.7449    0.7935    0.7684        92\n",
            "           $     1.0000    0.9894    0.9947        94\n",
            "          RP     0.8500    0.6415    0.7312       106\n",
            "         WRB     1.0000    1.0000    1.0000        74\n",
            "         JJS     0.9600    0.8571    0.9057        56\n",
            "         RBR     0.6071    0.3953    0.4789        43\n",
            "          EX     0.9706    0.9706    0.9706        34\n",
            "          FW     0.4348    0.3030    0.3571        33\n",
            "          ''     0.7368    1.0000    0.8485        14\n",
            "          LS     0.0000    0.0000    0.0000        23\n",
            "         WP$     1.0000    1.0000    1.0000         9\n",
            "         RBS     1.0000    0.8889    0.9412         9\n",
            "         PDT     0.5714    0.5714    0.5714         7\n",
            "          UH     0.0000    0.0000    0.0000         7\n",
            "\n",
            "    accuracy                         0.9477     46666\n",
            "   macro avg     0.8759    0.8525    0.8617     46666\n",
            "weighted avg     0.9463    0.9477    0.9465     46666\n",
            "\n",
            "2023-05-30 22:47:06,802 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_score': 0.9477135387648395,\n",
              " 'dev_score_history': [0.9182791112489821,\n",
              "  0.936251890340843,\n",
              "  0.9406529915855597,\n",
              "  0.9425336383729497,\n",
              "  0.9458490053898949,\n",
              "  0.945674512389003,\n",
              "  0.9479816976230175,\n",
              "  0.9475163829539727,\n",
              "  0.9490286556283687,\n",
              "  0.950191942300981],\n",
              " 'train_loss_history': [0.8807995968456774,\n",
              "  0.37887454598271897,\n",
              "  0.3170600586820653,\n",
              "  0.2862336966760508,\n",
              "  0.26562666665387286,\n",
              "  0.24918695575784766,\n",
              "  0.23781170831255774,\n",
              "  0.2275447439219562,\n",
              "  0.22118752872874473,\n",
              "  0.21084565979319275],\n",
              " 'dev_loss_history': [0.32081106305122375,\n",
              "  0.2370283156633377,\n",
              "  0.21967707574367523,\n",
              "  0.2059210240840912,\n",
              "  0.1955457329750061,\n",
              "  0.20099389553070068,\n",
              "  0.18899358808994293,\n",
              "  0.18794719874858856,\n",
              "  0.1829584538936615,\n",
              "  0.18061773478984833]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}